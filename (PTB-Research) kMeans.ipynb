{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ipLAvhTRXCQ"
   },
   "source": [
    "# $k$-Means and Cluster Storing\n",
    "\n",
    "Author: `Márcio Lopes Jr` \n",
    "\n",
    "*Master's student of `Computer Engineering, Intelligent Information Processing` at UFRN-Natal*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yy9TsWcXq66W"
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSZz804hFXSZ"
   },
   "source": [
    "## Paths for Clustering Files\n",
    "\n",
    "Municipality classification $ A_c $ -> **`Ac.csv`**\n",
    "\n",
    "Cluster centres $ C_{ci} $ -> **`Cci.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHSi-2SVdt1m",
    "outputId": "0b6493df-8e30-4667-e0aa-89da1e68d143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/The Sound of Drums/Notebooks/data/tests4/km_figure_{}C_{}T.svg\n"
     ]
    }
   ],
   "source": [
    "# Subfolder to store cluster data\n",
    "res_subfolder = \"files\"\n",
    "\n",
    "# Cluster data files\n",
    "path_cities_classes = f\"data/{res_subfolder}/Ac.csv\"\n",
    "path_cluster_centres_abs = f\"data/{res_subfolder}/Cci.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtYlhx-6RTst"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Steps:\n",
    "1. Create data copy without outliers\n",
    "2. Normalise datasets\n",
    "3. Keep record of the general mean (mean value of features for all municipalities)\n",
    "4. Reduce datasets with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jm0P6UyHp3kq"
   },
   "outputs": [],
   "source": [
    "# Loads data\n",
    "df = pd.read_csv(\"data/A0.csv\").set_index('cd_ibge')\n",
    "\n",
    "# training df without outliers\n",
    "lower, upper = df.ptb_rate.mean() - (df.ptb_rate.std()*3), df.ptb_rate.mean() + (df.ptb_rate.std()*3)\n",
    "df_train = df[(df.ptb_rate > lower) & (df.ptb_rate < upper)]\n",
    "df_copy = df.copy()\n",
    "\n",
    "# preprocessing transformers\n",
    "normalizer = Normalizer()\n",
    "yeojohnson = PowerTransformer()\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "# Transformed train sample\n",
    "train_sample = df_train.copy()\n",
    "train_sample[:] = minmax.fit_transform(yeojohnson.fit_transform(normalizer.fit_transform(train_sample)))\n",
    "sample = df.copy()\n",
    "sample[:] = minmax.fit_transform(yeojohnson.fit_transform(normalizer.fit_transform(sample)))\n",
    "\n",
    "# Reducing a few dimensions with PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(train_sample.iloc[:,:-3])\n",
    "pca_train_sample = pd.DataFrame(pca.transform(train_sample.iloc[:,:-3]))\n",
    "pca_sample = pd.DataFrame(pca.transform(sample.iloc[:,:-3]))\n",
    "pca_sample.index = sample.index\n",
    "pca_train_sample.index = train_sample.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Block - Clustering\n",
    "\n",
    "Steps:\n",
    "1. Train k-means on `pca_train_sample` (no outliers)\n",
    "2. Generate clusters on `pca_sample` (all included)\n",
    "3. Save municipalities' clusters to external file\n",
    "4. Calculate cluster PTB means\n",
    "5. If mean is above/below threshold, save cluster centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcqxKftd9-dR"
   },
   "outputs": [],
   "source": [
    "min_cluster = 2\n",
    "max_cluster = 30\n",
    "runs = 10\n",
    "threshold = .1\n",
    "\n",
    "for i in range(min_cluster, max_cluster+1):\n",
    "    print('', end='\\r')\n",
    "    \n",
    "    for t in range(0, runs):\n",
    "        # Find clusters for i clusters\n",
    "        km = KMeans(i, init='random', max_iter=10000, algorithm='full', tol=1e-7)\n",
    "        km.fit(pca_train_sample)\n",
    "        df2 = sample.copy()\n",
    "        pred = km.predict(pca_sample)\n",
    "        df2['cluster'] = km.predict(pca_sample)\n",
    "        sample['cluster'] = pred\n",
    "        df_copy['cluster'] = pred\n",
    "        df2['ptb_rate'] = df.ptb_rate\n",
    "\n",
    "        # Store cities' clusters for each test round\n",
    "        log_cidades = df2[['ptb_rate', 'cluster']].copy()\n",
    "        log_cidades['test_number'] = t\n",
    "        log_cidades['n_clusters'] = i\n",
    "        log_cidades.to_csv(path_cities_classes,  mode='a', header=(not os.path.exists(path_cities_classes)))\n",
    "\n",
    "        # Get clusters PTB mean for selection \n",
    "        distribution = df_copy.groupby(['cluster']).agg({'ptb_rate':['mean', 'median']})\n",
    "        distribution.columns = ['media', 'mediana']\n",
    "        sample.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "        df_copy.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "        \n",
    "        # Select clusters above and below threshold\n",
    "        large_ptb_rate_groups = distribution[(distribution.media > (1+threshold)*df.ptb_rate.mean())].index.values\n",
    "        small_ptb_rate_groups = distribution[(distribution.media < (1-threshold)*df.ptb_rate.mean())].index.values\n",
    "        groups_to_analyse = list(large_ptb_rate_groups) + list(small_ptb_rate_groups)\n",
    "        \n",
    "        df2['type_of_cluster'] = np.int64(df2.cluster.isin(large_ptb_rate_groups)) - np.int64(df2.cluster.isin(small_ptb_rate_groups))\n",
    "        print(i, t, len(large_ptb_rate_groups), len(small_ptb_rate_groups))\n",
    "\n",
    "        # Individual group analysis\n",
    "        for c in groups_to_analyse:\n",
    "            # Absolute centre (median)\n",
    "            arr = pd.Series(df_copy[df2.cluster == c].median(axis=0))\n",
    "            arr.index = sample.columns\n",
    "            arr_df = pd.DataFrame(arr).reset_index().pivot_table(columns=df_copy.columns)\n",
    "            arr_df['cluster'] = c\n",
    "            arr_df['test_number'] = t\n",
    "            arr_df['n_clusters'] = i\n",
    "            arr_df.to_csv(path_cluster_centres_abs, mode='a', header=(not os.path.exists(path_cluster_centres_abs)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(UFRN/Mestrado/Pesquisa) Teste de Clusterização - Versão Código.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
