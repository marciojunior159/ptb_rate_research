{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slOjxmxqCUsn"
   },
   "source": [
    "# Creation of Municipal Socioeconomic Dataset\n",
    "\n",
    "Source: Federal Government of Brazil's Cadastro Único (CadÚnico/Cadu)\n",
    "\n",
    "Author: `Márcio Lopes Jr` \n",
    "\n",
    "*Master's student of `Computer Engineering, Intelligent Information Processing` at UFRN-Natal*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxiP4hQFCUtI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cat_list = []\n",
    "val_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbzS8De2CUtM"
   },
   "source": [
    "**Vartiable Classification Function**\n",
    "\n",
    "Simple function that attemps to recognise categorical variables. Deciding factors were based on previous knowledge of data, so not a universal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1lmrYVqCUtO"
   },
   "outputs": [],
   "source": [
    "def get_vartypes(df):\n",
    "    global cat_list, val_list\n",
    "    cat_list = []\n",
    "    val_list = []\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() == 2:\n",
    "            val_list.append(col)\n",
    "        elif (df[col].nunique() < 21) & \\\n",
    "           (col not in ['qtde_pessoas', 'qtd_comodos_domic_fam', 'qtd_comodos_dormitorio_fam', \n",
    "                        'cod_ano_serie_frequenta_memb', 'cod_ano_serie_frequentou_memb', 'qtd_meses_12_meses_memb']):\n",
    "            cat_list.append(col)\n",
    "        else:\n",
    "            val_list.append(col)\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of Binary Functions**\n",
    "\n",
    "Exceptional case, categorical columns will be transformed in more the one column (one per category), but in the case of binary variables, only one column will be used, as the categories (2) are complementary anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrhhSzBstNpL"
   },
   "outputs": [],
   "source": [
    "binary = ['cod_sabe_ler_escrever_memb', 'cod_deficiencia_memb', 'cod_escola_local_memb', 'cod_concluiu_frequentou_memb', \n",
    "          'cod_trabalhou_memb', 'cod_afastado_trab_memb', 'cod_agricultura_trab_memb', 'cod_trabalho_12_meses_memb', \n",
    "          'cod_local_domic_fam', 'cod_agua_canalizada_fam', 'cod_banheiro_domic_fam', 'cod_familia_indigena_fam', \n",
    "          'ind_familia_quilombola_fam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translations of Codes to Definitions**\n",
    "\n",
    "In order to rename columns in a more meaningful way. In Education case, translation dictionaries are also used to join columns of past and present education levels, which have different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irS2Ic3rOMjB"
   },
   "outputs": [],
   "source": [
    "# Personal data\n",
    "freq_to_freq = {1:1, 2:2, 3:3, 4:4, 5:4, 6:5, 7:6, 8:7, 9:8, 10:9, 11:10, 12:11, 14:12, 13:13, 14:14, 15:15}\n",
    "\n",
    "freq_reduce =  {1 : 'pre', \n",
    "                2 : 'pre', \n",
    "                3 : 'alfa', \n",
    "                4 : 'fund', \n",
    "                5 : 'fund', \n",
    "                6 : 'fund', \n",
    "                7 : 'medio', \n",
    "                8 : 'medio', \n",
    "                9 : 'eja_fund', \n",
    "                10 : 'eja_fund', \n",
    "                11 : 'eja_medio', \n",
    "                12 : 'alfa_adultos', \n",
    "                13 : 'superior', \n",
    "                14 : 'pre_vest', \n",
    "                15 : 'nenhum'}\n",
    "\n",
    "trab_translate = {1 : 'autonomo_bico', \n",
    "                  2 : 'temp_rural', \n",
    "                  3 : 'sem_carteira_ass', \n",
    "                  4 : 'com_carteira_ass', \n",
    "                  5 : 'dom_sem_carteira_ass', \n",
    "                  6 : 'dom_com_carteira_ass', \n",
    "                  7 : 'nao_remunerado', \n",
    "                  8 : 'militar_ou_servidor', \n",
    "                  9 : 'empregador', \n",
    "                  10 : 'estagiario',\n",
    "                  11 : 'aprendiz'}\n",
    "\n",
    "escola_translate = {1 : 'rede_publica', \n",
    "                    2 : 'rede_particular', \n",
    "                    3 : 'ja_frequentou', \n",
    "                    4 : 'nunca'}\n",
    "\n",
    "raca_translate = {1 : 'branca', \n",
    "                  2 : 'preta', \n",
    "                  3 : 'amarela', \n",
    "                  4 : 'parda'}\n",
    "\n",
    "# Household data\n",
    "piso_translate = {1 : 'terra', \n",
    "                  2 : 'cimento', \n",
    "                  3 : 'madeira_aproveitada',\n",
    "                  4 : 'madeira_aparelhada', \n",
    "                  5 : 'ceramica_lajota_pedra', \n",
    "                  6 : 'carpete'}\n",
    "\n",
    "mat_translate = {1 : 'alvenaria_tijolo_revestido', \n",
    "                 2 : 'alvenaria_tijolo_nao_revestido', \n",
    "                 3 : 'madeira_aparelhada', \n",
    "                 4 : 'taipa_revestida', \n",
    "                 5 : 'taipa_nao_revestida', \n",
    "                 6 : 'madeira_aproveitada', \n",
    "                 7 : 'palha'}\n",
    "\n",
    "abaste_translate = {1 : 'rede_geral_dist', \n",
    "                    2 : 'poco_nascente', \n",
    "                    3 : 'cisterna', \n",
    "                    4 : 'outro'}\n",
    "\n",
    "sanea_translate = {1 : 'rede_esgoto_pluvial', \n",
    "                   2 : 'fossa_septica', \n",
    "                   3 : 'fossa_rudimentar', \n",
    "                   4 : 'vala_ceu_aberto', \n",
    "                   5 : 'rio_lago_mar'}\n",
    "\n",
    "lixo_translate = {1 : 'coletado_diretamento', \n",
    "                  2 : 'coletado_indiretamente', \n",
    "                  3 : 'queimado_enterrado_propr', \n",
    "                  4 : 'terreno_baldio_logradouro', \n",
    "                  5 : 'rio_mar'}\n",
    "\n",
    "iluminacao_translate = {1 : 'eletr_medidor_proprio', \n",
    "                        2 : 'eletr_medidor_comunitario', \n",
    "                        3 : 'eletr_sem_medidor', \n",
    "                        4 : 'oleo_gas_querosene', \n",
    "                        5 : 'vela'}\n",
    "\n",
    "calcamento_translate = {1 : 'total', \n",
    "                        2 : 'parcial', \n",
    "                        3 : 'nenhum'}\n",
    "\n",
    "grupo_translate = {101 : 'cigana', \n",
    "                   201 : 'extrativista', \n",
    "                   202 : 'pesca_artesanal', \n",
    "                   203 : 'comunid_terreiro', \n",
    "                   204 : 'ribeirinha', \n",
    "                   205 : 'agricultura_familiar', \n",
    "                   301 : 'assentada_reforma_agraria', \n",
    "                   302 : 'benef_prog_nac_cred_fundiario', \n",
    "                   303 : 'acampada', \n",
    "                   304 : 'atingida_empreend_infra', \n",
    "                   305 : 'preso_sist_carcerario', \n",
    "                   306 : 'catadores'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfKsW2ZHCtmM"
   },
   "source": [
    "**Personal-level data processing**\n",
    "\n",
    "Needs to be run first, as only the families of these members will be included in the family calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rf65rQLoCUtR",
    "outputId": "5bd9c768-d81c-4de2-a243-0baf700ad6f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame()\n",
    "familias = []\n",
    "varset = False\n",
    "\n",
    "for chunk in pd.read_csv(\"data/base_amostra_pessoa_201812.csv\", sep=';', decimal=',', chunksize=500000):\n",
    "    c = chunk.drop(columns=['estrato', 'classf', 'id_pessoa', 'cod_parentesco_rf_pessoa', \n",
    "                            'peso.fam', 'peso.pes', 'cod_local_nascimento_pessoa', \n",
    "                            'cod_certidao_registrada_pessoa', 'cod_ano_serie_frequentou_memb'])\n",
    "    \n",
    "    print(c.shape)\n",
    "    c = c[(c.idade > 13) & (c.idade < 41) & (c.cod_sexo_pessoa == 2)]\n",
    "    familias = familias + c.id_familia.unique().tolist()\n",
    "\n",
    "    print(c[['val_remuner_emprego_memb', 'val_renda_doacao_memb', 'val_renda_aposent_memb', 'val_renda_seguro_desemp_memb', 'val_renda_pensao_alimen_memb' , 'val_outras_rendas_memb']].sum(axis=1).sum(), c['val_renda_bruta_12_meses_memb'].sum()/13)\n",
    "\n",
    "    for col in c.columns:\n",
    "        if col in binary:\n",
    "            c[col] = c[col].map({2:0, 1:1})\n",
    "\n",
    "    c['cod_curso_frequentou_pessoa_memb'] = c.cod_curso_frequentou_pessoa_memb.map(freq_to_freq)\n",
    "    c['cod_curso_memb'] = np.where(c.cod_curso_frequenta_memb.notnull(), c.cod_curso_frequenta_memb, \n",
    "                                   c.cod_curso_frequentou_pessoa_memb)\n",
    "    c['cod_curso_memb'] = c.cod_curso_memb.map(freq_reduce)\n",
    "    \n",
    "    c['cod_principal_trab_memb'] = c.cod_principal_trab_memb.map(trab_translate)\n",
    "    c['ind_frequenta_escola_memb'] = c.ind_frequenta_escola_memb.map(escola_translate)\n",
    "    c['cod_raca_cor_pessoa'] = c.cod_raca_cor_pessoa.map(raca_translate)\n",
    "    c.drop(columns=['cod_curso_frequentou_pessoa_memb', 'cod_curso_frequenta_memb', \n",
    "                    'cod_ano_serie_frequenta_memb', 'cod_ano_serie_frequentou_memb', \n",
    "                    'cod_sexo_pessoa'], inplace=True, errors='ignore')\n",
    "    \n",
    "    if varset == False: varset = get_vartypes(c)\n",
    "        \n",
    "    c = pd.get_dummies(c, columns=cat_list)\n",
    "\n",
    "    numero = c.groupby('cd_ibge', as_index=False)[['id_familia']].count().rename(columns={'id_familia':'qnt'})\n",
    "    c = c.groupby('cd_ibge', as_index=False).mean()\n",
    "    meancols = list(c.columns)\n",
    "    c = c.merge(numero, on='cd_ibge')\n",
    "    c[meancols[2:]] = c[meancols[2:]].multiply(c['qnt'], axis='index')\n",
    "    df_p = df_p.append(c).fillna(0)\n",
    "    print(df_p.shape)\n",
    "    \n",
    "    \n",
    "df_pp = df_p.groupby('cd_ibge').sum()\n",
    "df_pp = df_pp.divide(df_pp.qnt, axis=0).drop(columns=['id_familia', 'qnt'])\n",
    "print(df_pp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjHNJgehD1UH"
   },
   "source": [
    "**Household-level data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zk7sKgi7CUtZ",
    "outputId": "99b5ad87-1dc8-4ec3-af8a-32b31fa123f8"
   },
   "outputs": [],
   "source": [
    "# Base de amostras familiares anonimizadas do CADU \n",
    "df = pd.DataFrame()\n",
    "varset = False\n",
    "for chunk in pd.read_csv(\"data/base_amostra_familia_201812.csv\", sep=';', decimal=',', chunksize=500000, low_memory=False):\n",
    "    c = chunk.drop(columns=['estrato', 'classf', 'dat_cadastramento_fam', 'dat_alteracao_fam', \n",
    "                            'dat_atualizacao_familia', 'peso.fam', 'cod_centro_assist_fam', 'cod_eas_fam'])\n",
    "    print(c.shape)\n",
    "    c = c[(c.id_familia.isin(familias))]\n",
    "\n",
    "    for col in c.columns:\n",
    "        if col in binary:\n",
    "            c[col] = c[col].map({2:0, 1:1})\n",
    "\n",
    "    c['cod_material_piso_fam'] = c.cod_material_piso_fam.map(piso_translate)\n",
    "    c['cod_material_domic_fam'] = c.cod_material_domic_fam.map(mat_translate)\n",
    "    c['cod_abaste_agua_domic_fam'] = c.cod_abaste_agua_domic_fam.map(abaste_translate)\n",
    "    c['cod_escoa_sanitario_domic_fam'] = c.cod_escoa_sanitario_domic_fam.map(sanea_translate)\n",
    "    c['cod_destino_lixo_domic_fam'] = c.cod_destino_lixo_domic_fam.map(lixo_translate)\n",
    "    c['cod_iluminacao_domic_fam'] = c.cod_iluminacao_domic_fam.map(iluminacao_translate)\n",
    "    c['cod_calcamento_domic_fam'] = c.cod_calcamento_domic_fam.map(calcamento_translate)\n",
    "    c['ind_parc_mds_fam'] = c.ind_parc_mds_fam.map(grupo_translate)\n",
    "    \n",
    "    if varset == False: varset = get_vartypes(c)\n",
    "        \n",
    "    c = pd.get_dummies(c, columns=cat_list)\n",
    "    numero = c.groupby('cd_ibge', as_index=False)[['id_familia']].count().rename(columns={'id_familia':'qnt'})\n",
    "    c = c.groupby('cd_ibge', as_index=False).mean()\n",
    "    meancols = list(c.columns)\n",
    "    c = c.merge(numero, on='cd_ibge')\n",
    "    c[meancols[2:]] = c[meancols[2:]].multiply(c['qnt'], axis='index')\n",
    "    \n",
    "    df = df.append(c).fillna(0)\n",
    "    print(df.shape)\n",
    "    \n",
    "\n",
    "df_pes = df.groupby('cd_ibge').sum()\n",
    "df_pes = df_pes.divide(df_pes.qnt, axis=0).drop(columns=['id_familia', 'qnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg-0-7qCCUtj"
   },
   "outputs": [],
   "source": [
    "# Join personal and household data by municipality\n",
    "df_final = df_pp.join(df_pes).reset_index()\n",
    "\n",
    "# Add PTB data from the SINASC dataset\n",
    "ptb_rate_df = pd.read_csv(\"data/ptb_by_municipality.csv\")\n",
    "df_final = df_final.merge(ptb_rate_df, on='cd_ibge')\n",
    "\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Education Addition**\n",
    "\n",
    "A municipality with high Middle School education, for instance, will show a small percentage of Primary School education after the application of One-Hot Encoding, but since to study at a certain Education level, one must finish the previous level, the percentage of people at a given level was added to the percentage of people of its previous levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh0X9hFFBgxB"
   },
   "outputs": [],
   "source": [
    "df_final['cod_curso_memb_pre_vest'] += df_final['cod_curso_memb_superior']\n",
    "df_final['cod_curso_memb_medio'] += df_final['cod_curso_memb_pre_vest'] + df_final['cod_curso_memb_eja_medio']\n",
    "df_final['cod_curso_memb_fund'] += df_final['cod_curso_memb_medio'] + df_final['cod_curso_memb_eja_fund']\n",
    "df_final['cod_curso_memb_alfa'] += df_final['cod_curso_memb_fund'] + df_final['cod_curso_memb_alfa_adultos']\n",
    "df_final['cod_curso_memb_pre'] += df_final['cod_curso_memb_alfa']\n",
    "df_final['cod_curso_memb_eja'] = df_final['cod_curso_memb_eja_fund'] + df_final['cod_curso_memb_eja_medio'] + df_final['cod_curso_memb_alfa_adultos']\n",
    "\n",
    "df_final = df_final.drop(columns=['cod_curso_memb_eja_medio', 'cod_curso_memb_eja_fund', 'cod_curso_memb_alfa_adultos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xbjNyodCUtl"
   },
   "outputs": [],
   "source": [
    "df_final.to_csv(\"data/pos_means.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(UFRN/Mestrado/Pesquisa) Dados do CADU por Município.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
